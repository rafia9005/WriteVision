{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOzwnf42gyQL6OUncbssSlC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafia9005/WriteVision/blob/main/jp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "init project"
      ],
      "metadata": {
        "id": "NPHfOUlmN9Hm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C2nwbJUNL9rU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "import requests\n",
        "import base64\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup logger\n",
        "def setup_logger():\n",
        "  logger = logging.getLogger(\"WritterVision\")\n",
        "  logger.setLevel(logging.INFO)\n",
        "\n",
        "  handler = logging.StreamHandler()\n",
        "  formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
        "  handler.setFormatter(formatter)\n",
        "  logger.addHandler(handler)\n",
        "  return logger"
      ],
      "metadata": {
        "id": "l6rnwf4aN4HQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "logger = setup_logger()\n",
        "\n",
        "def load_model(model_directory=\"./model\"):\n",
        "    \"\"\"\n",
        "    Load model and processor. If a local model exists in the specified directory, load from there.\n",
        "    Otherwise, download from Hugging Face and save locally.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      if os.path.exists(model_directory) and os.path.isdir(model_directory):\n",
        "        processor = TrOCRProcessor.from_pretrained(model_directory)\n",
        "        model = VisionEncoderDecoderModel.from_pretrained(model_directory)\n",
        "        logger.info(\"Model and processor loaded from local directory.\")\n",
        "      else:\n",
        "        logger.info(\"Local model directory not found. Downloading model and processor from Hugging Face.\")\n",
        "        processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
        "        model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
        "        model.save_pretrained(model_directory)\n",
        "        processor.save_pretrained(model_directory)\n",
        "        logger.info(\"Model and processor downloaded and saved locally.\")\n",
        "\n",
        "      return processor, model\n",
        "    except Exception as e:\n",
        "      logger.error(f\"Error loading model and processor: {e}\")\n",
        "      raise"
      ],
      "metadata": {
        "id": "_cjfvYrtOZXI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(input_type: str, source: str):\n",
        "    if input_type == \"url\":\n",
        "        return load_image_from_url(source)\n",
        "    elif input_type == \"path\":\n",
        "        return load_image_from_path(source)\n",
        "    elif input_type == \"base64\":\n",
        "        return load_image_from_base64(source)\n",
        "    else:\n",
        "        error_msg = \"Invalid input type. Use 'url', 'path', or 'base64'.\"\n",
        "        logger.error(error_msg)\n",
        "        raise ValueError(error_msg)\n",
        "\n",
        "def load_image_from_url(url: str):\n",
        "    try:\n",
        "        logger.info(f\"Loading image from URL: {url}\")\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Memeriksa status HTTP\n",
        "        image = Image.open(response.raw).convert(\"RGB\")\n",
        "        logger.info(\"Image successfully loaded from URL.\")\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Failed to load image from URL: {e}\"\n",
        "        logger.error(error_msg)\n",
        "        raise Exception(error_msg)\n",
        "\n",
        "def load_image_from_path(path: str):\n",
        "    try:\n",
        "        logger.info(f\"Loading image from path: {path}\")\n",
        "        image = Image.open(path).convert(\"RGB\")\n",
        "        logger.info(\"Image successfully loaded from path.\")\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Failed to load image from path: {e}\"\n",
        "        logger.error(error_msg)\n",
        "        raise Exception(error_msg)\n",
        "\n",
        "def load_image_from_base64(base64_str: str):\n",
        "    try:\n",
        "        logger.info(\"Loading image from base64 string.\")\n",
        "        image_data = base64.b64decode(base64_str)\n",
        "        image = Image.open(BytesIO(image_data)).convert(\"RGB\")\n",
        "        logger.info(\"Image successfully loaded from base64.\")\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Failed to load image from base64: {e}\"\n",
        "        logger.error(error_msg)\n",
        "        raise Exception(error_msg)"
      ],
      "metadata": {
        "id": "sfWToTz6PbQy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utils configure\n",
        "def print_result(generated_text: str):\n",
        "    logger.info(\"Generated Text:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(generated_text)\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "def validate_generated_text(text: str):\n",
        "    if not text.strip():\n",
        "        logger.warning(\"Generated text is empty.\")\n",
        "        return False\n",
        "    if len(text) > 500:  # Arbitrary limit\n",
        "        logger.warning(\"Generated text is too long.\")\n",
        "        return False\n",
        "    logger.info(\"Generated text passed validation.\")\n",
        "    return True"
      ],
      "metadata": {
        "id": "st9n7bcePnfM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    input_type = input(\"Enter input type ('url', 'path', or 'base64'): \").strip().lower()\n",
        "    source = input(\"Enter the source (URL, file path, or base64 string): \").strip()\n",
        "\n",
        "    try:\n",
        "        logger.info(\"Loading image...\")\n",
        "        image = load_image(input_type, source)\n",
        "\n",
        "        logger.info(\"Loading model...\")\n",
        "        processor, model = load_model()\n",
        "\n",
        "        logger.info(\"Processing image...\")\n",
        "        pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
        "        generated_ids = model.generate(pixel_values)\n",
        "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "        if validate_generated_text(generated_text):\n",
        "            print_result(generated_text)\n",
        "        else:\n",
        "            logger.warning(\"Generated text failed validation.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"An error occurred: {e}\")\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grmCA8q3PzrI",
        "outputId": "aff3396d-c6cd-486b-e7ab-4d253e314891"
      },
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter input type ('url', 'path', or 'base64'): url\n",
            "Enter the source (URL, file path, or base64 string): https://asset-2.tstatic.net/jogja/foto/bank/images/tulisan-tangan-mirip-komputer_20151008_113306.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-18 16:36:01,932 - WritterVision - INFO - Loading image...\n",
            "2025-01-18 16:36:01,932 - WritterVision - INFO - Loading image...\n",
            "INFO:WritterVision:Loading image...\n",
            "2025-01-18 16:36:01,936 - WritterVision - INFO - Loading image from URL: https://asset-2.tstatic.net/jogja/foto/bank/images/tulisan-tangan-mirip-komputer_20151008_113306.jpg\n",
            "2025-01-18 16:36:01,936 - WritterVision - INFO - Loading image from URL: https://asset-2.tstatic.net/jogja/foto/bank/images/tulisan-tangan-mirip-komputer_20151008_113306.jpg\n",
            "INFO:WritterVision:Loading image from URL: https://asset-2.tstatic.net/jogja/foto/bank/images/tulisan-tangan-mirip-komputer_20151008_113306.jpg\n",
            "2025-01-18 16:36:02,638 - WritterVision - INFO - Image successfully loaded from URL.\n",
            "2025-01-18 16:36:02,638 - WritterVision - INFO - Image successfully loaded from URL.\n",
            "INFO:WritterVision:Image successfully loaded from URL.\n",
            "2025-01-18 16:36:02,642 - WritterVision - INFO - Loading model...\n",
            "2025-01-18 16:36:02,642 - WritterVision - INFO - Loading model...\n",
            "INFO:WritterVision:Loading model...\n",
            "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"image_size\": 384,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"qkv_bias\": false,\n",
            "  \"transformers_version\": \"4.47.1\"\n",
            "}\n",
            "\n",
            "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"cross_attention_hidden_size\": 768,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_decoder\": true,\n",
            "  \"layernorm_embedding\": true,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"trocr\",\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"use_cache\": false,\n",
            "  \"use_learned_position_embeddings\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "2025-01-18 16:36:08,949 - WritterVision - INFO - Model and processor loaded from local directory.\n",
            "2025-01-18 16:36:08,949 - WritterVision - INFO - Model and processor loaded from local directory.\n",
            "INFO:WritterVision:Model and processor loaded from local directory.\n",
            "2025-01-18 16:36:08,954 - WritterVision - INFO - Processing image...\n",
            "2025-01-18 16:36:08,954 - WritterVision - INFO - Processing image...\n",
            "INFO:WritterVision:Processing image...\n",
            "2025-01-18 16:36:13,737 - WritterVision - INFO - Generated text passed validation.\n",
            "2025-01-18 16:36:13,737 - WritterVision - INFO - Generated text passed validation.\n",
            "INFO:WritterVision:Generated text passed validation.\n",
            "2025-01-18 16:36:13,745 - WritterVision - INFO - Generated Text:\n",
            "2025-01-18 16:36:13,745 - WritterVision - INFO - Generated Text:\n",
            "INFO:WritterVision:Generated Text:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "Lancashire County Courthouse\n",
            "----------------------------------------\n"
          ]
        }
      ]
    }
  ]
}